{
  "name": "bedrock-proxy-endpoint",
  "version": "2.1.0",
  "description": "ðŸ”€ Bedrock Proxy Endpoint â‡¢ Spin up your own custom OpenAI API server endpoint for easy AWS Bedrock inference (using standard `baseUrl`, and `apiKey` params)",
  "main": "server.js",
  "type": "module",
  "scripts": {
    "clean": "rm -rf node_modules && rm -rf package-lock.json && npm install"
  },
  "keywords": [
    "openai",
    "bedrock",
    "aws",
    "proxy",
    "wrapper",
    "serverless",
    "inference",
    "llm"
  ],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "bedrock-wrapper": "^2.2.0",
    "body-parser": "^1.20.3",
    "dotenv": "^16.4.7",
    "express": "^4.21.2",
    "express-rate-limit": "^7.5.0"
  }
}
