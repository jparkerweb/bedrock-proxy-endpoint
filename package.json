{
  "name": "bedrock-proxy-endpoint",
  "version": "2.0.0",
  "description": "ðŸ”€ Bedrock Proxy Endpoint â‡¢ Spin up your own custom OpenAI API server endpoint for easy AWS Bedrock inference (using standard `baseUrl`, and `apiKey` params)",
  "main": "server.js",
  "type": "module",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "openai",
    "bedrock",
    "aws",
    "proxy",
    "wrapper",
    "serverless",
    "inference",
    "llm"
  ],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "bedrock-wrapper": "^2.0.0",
    "body-parser": "^1.20.3",
    "dotenv": "^16.4.5",
    "express": "^4.21.1",
    "express-rate-limit": "^7.4.1"
  }
}
